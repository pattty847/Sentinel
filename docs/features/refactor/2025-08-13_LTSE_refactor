TL;DR: You’re doing work 3–5× too many times. The killers are: **(1)** maps keyed by `double` for price, **(2)** fanning the same snapshot into *every* timeframe, **(3)** scanning the whole slice to detect “disappearing” levels, and **(4)** storing big snapshot structures you re-walk. Convert to **tick-indexed ints**, emit **one base column** per tick window, derive other timeframes via **rolling sums/mips**, and replace disappear-detection with a **version counter**. You’ll cut CPU by an order of magnitude and unlock 10k+ cells at 60–120 FPS.

---

## What’s biting you right now

1. **`std::map<double,…>`** for price → cache-miss city, tree overhead, and floating-point key drift.
2. **`updateAllTimeframes()`** pushes the same snapshot through N timeframes. That’s N× work per message.
3. **`updateDisappearingLevels()`** loops all levels and does `find` in a map each snapshot → O(L) per frame just for “gone?” checks.
4. **Viewport filtering at aggregation**: when you zoom out past your buffer, you create **real data gaps** in the base series. Aggregation shouldn’t care about viewport.
5. **`system_clock::now()`** for snapshot timestamp ≠ exchange time → time-bucketing skew under jitter/reconnects.

---

## Minimal-change fix kit (keep your design, remove the landmines)

### 1) Price = integer tick, not double

```cpp
// Replace double prices everywhere inside LTSE:
using Tick = int32_t; // priceIndex = round(price / tickSize)

// Quantize once:
inline Tick priceToTick(double price) const {
    return static_cast<Tick>(std::llround(price / m_priceResolution));
}
inline double tickToPrice(Tick t) const { return double(t) * m_priceResolution; }
```

* Swap all `std::map<double,Metrics>` to **flat hash** keyed by `Tick`.

  * If you can: `tsl::robin_map<Tick, Metrics>` or `ankerl::unordered_dense`.
  * If you must stay std: `std::unordered_map<Tick, Metrics>` with `reserve()` (but robin/dense is much faster).

### 2) Stop fanning snapshots into all timeframes

* **Keep a single base timeframe** (e.g., 100 ms). Emit **one column** per base window.
* Maintain coarser frames as **rolling sums** over base columns or do **time mips** on GPU. No more `for (timeframe : m_timeframes) updateTimeframe(...)`.

Replace:

```cpp
void LiquidityTimeSeriesEngine::updateAllTimeframes(const OrderBookSnapshot& s){
  for (auto tf: m_timeframes) updateTimeframe(tf, s);
}
```

with:

```cpp
// Only build the current base slice here
updateBaseTimeframe(m_baseTimeframe_ms, snapshot);
```

And maintain coarser frames with **rolling windows**:

```cpp
// For each coarser tf = base * K
// keep a deque of last K base columns (tick-indexed sums)
// current_coarser_col = previous + base_col_new - base_col_oldest
```

This makes coarser timeframes **O(#dirty\_levels)** instead of O(#levels × #timeframes).

### 3) Kill “disappearing level” scans with a version stamp

No more looping every price to check presence. Use a **global `uint32_t snapshot_seq`**:

```cpp
struct PriceLevelMetrics {
    // ...your fields...
    uint32_t lastSeenSeq = 0; // new
};

uint32_t gSeq = 0;

void addSnapshotToSlice(LiquidityTimeSlice& slice, const Snapshot& s) {
    ++gSeq;
    for (auto& [tick, sz] : s.bids) {
        auto& m = slice.bidMetrics[tick];
        updateMetrics(m, sz, s.timestamp_ms, slice);
        m.lastSeenSeq = gSeq;
    }
    for (auto& [tick, sz] : s.asks) {
        auto& m = slice.askMetrics[tick];
        updateMetrics(m, sz, s.timestamp_ms, slice);
        m.lastSeenSeq = gSeq;
    }
    // Remove the O(L) disappears pass:
    // Any level with m.lastSeenSeq != gSeq simply wasn't present *this* snapshot.
    // Persistence uses time, not per-snapshot scanning.
}
```

In `finalizeLiquiditySlice`, persistence is computed from `firstSeen_ms/lastSeen_ms` that you already maintain—no need to O(L) compare with the last snapshot.

### 4) Don’t filter by viewport during aggregation

* Build the **full base column** (or at least the visible tick-range + small fixed guard like ±500 ticks), independent of the current viewport.
* Viewport affects **render sampling**, not **data capture**. This prevents the gaps you observed.

### 5) Use **exchange timestamps** for bucketing

Replace `system_clock::now()` with the timestamp coming from the feed (or derive from sequence / server time). Buckets should be:

```cpp
int64_t sliceStart = (exchange_ts_ms / base_ms) * base_ms;
```

It eliminates slice splits when your local clock jitters.

---

## Fast path toward “10k cells without tears”

### A) Change your slice containers

Right now:

```cpp
std::map<double, Metrics> bidMetrics, askMetrics;
```

Move to:

```cpp
// Sparse but fast
robin_map<Tick, Metrics> bid, ask; 
bid.reserve(4096); ask.reserve(4096);
```

If you have a dense tick range (common for crypto with 0.01 ticks over a tight window), use a **compact vector window**:

```cpp
struct Slice {
  Tick minTick, maxTick;
  std::vector<Metrics> rows;    // rows[maxTick-minTick+1]
  std::vector<uint32_t> seenSeq;// parallel presence/version
};
```

Populate only dirty rows; keep a **bitset** for dirties to avoid touching zeros at emit time.

### B) Emit **column deltas** to the renderer

Expose:

```cpp
struct ColumnDelta {
  uint32_t col;       // time ring index
  Tick     minTick, maxTick;
  std::vector<uint16_t> packed; // or u8; bids/asks or signed
  std::vector<uint32_t> dirtyRows; // indices of rows we filled
};
```

Renderer uploads one column (or tiled chunks). No historical rewrites.

### C) Finalize slice without full scans

Your `finalizeLiquiditySlice` loops all metrics—fine—but ensure it’s **once per base window**, not repeated per timeframe. Persistence check becomes trivial (compare `(lastSeen_ms-firstSeen_ms)/duration_ms`).

---

## Micro-diffs (surgical edits)

**1) Replace `quantizePrice(double)`**

```cpp
double LiquidityTimeSeriesEngine::quantizePrice(double price) const {
    return std::round(price / m_priceResolution) * m_priceResolution; // ❌
}

// New:
Tick LiquidityTimeSeriesEngine::quantizeTick(double price) const {
    return static_cast<Tick>(std::llround(price / m_priceResolution));
}
```

Then everywhere: store **Tick**, not double. Only convert to price when rendering/tooltips.

**2) Snapshot building (no viewport filtering, reserve maps)**

```cpp
OrderBookSnapshot snapshot;
snapshot.timestamp_ms = book.exchange_ts_ms; // ✅

snapshot.bids.reserve(std::min<size_t>(limitedBook.bids.size(), 8192));
snapshot.asks.reserve(std::min<size_t>(limitedBook.asks.size(), 8192));

for (const auto& b : limitedBook.bids) {
    Tick t = quantizeTick(b.price);
    snapshot.bids[t] += b.size;
}
for (const auto& a : limitedBook.asks) {
    Tick t = quantizeTick(a.price);
    snapshot.asks[t] += a.size;
}
```

**3) Base-only update**

```cpp
void LiquidityTimeSeriesEngine::addOrderBookSnapshot(const OrderBook& book) {
    if (book.product_id.empty()) return;
    OrderBookSnapshot s = makeSnapshot(book); // as above
    m_snapshots.push_back(s);
    updateBaseTimeframe(m_baseTimeframe_ms, s); // only base
    cleanupOldData();
}
```

**4) Coarser timeframes via rolling sums**
Maintain for each coarser `tf = base*K`:

```cpp
struct RollingTf {
  int K;
  std::deque<ColumnDelta> lastK; // or a compact summed column
  ColumnDelta rollingSum;        // kept up to date
};
```

On new base column:

* push into `lastK`, add to `rollingSum`; if size> K, subtract popped column.
* Emit `rollingSum` as the `tf` column—**no re-aggregation from raw**.

---

## Rendering tie-in

* Heatmap is a **GPU ring texture**; each `ColumnDelta` → **single subimage upload (width=1)**.
* Colors via **1D LUT** in shader (no recolor uploads).
* Multi-timeframe view is just picking **which ring** you’re drawing from (base vs rolling LOD) or sampling a **time mip**.

---

## Sanity HUD (so you know it’s fixed)

On-screen counters (tiny monospace overlay):

* `cols/frame`, `bytes/frame`, `dirty rows/col`
* `CPU agg ms`, `GPU frame ms`, `draw calls`
* `base->coarser reuse %` (should be \~100%)
* `seq gap` warning if exchange sequence jumps

---

## Risk box (engineering mode)

**Thesis:** Converting to tick-indexed ints + base-only aggregation + version-stamp presence will remove the CPU hotspots and unblock 10k+ visible cells.
**Invalidation:** If Nsight shows GPU idle but CPU hot outside LTSE (e.g., JSON parse/locks), fix ingest (ring buffers, prealloc) before LTSE refactor.
**Metrics:** `cols/frame=1–2`, `upload ≤0.5–2 MB/s`, `agg ≤1.5 ms`, `GPU ≤8 ms`, `drawcalls=1–4`.
**Execution plan (tonight → weekend):**

1. **Tonight (1–2h):** Switch `double→Tick`, swap maps to robin/dense/unordered, remove viewport filtering at agg, use exchange ts.
2. **Tomorrow (3–4h):** Kill `updateAllTimeframes`; implement base-only + rolling-sum timeframes; remove `updateDisappearingLevels` pass.
3. **Weekend (4–6h):** Emit `ColumnDelta` and wire the ring-texture upload; add HUD; profile & set guards.